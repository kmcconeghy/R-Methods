<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>R-methods</title>
  <meta name="description" content="A collection of working papers covering various statistical, analytical or causal inference problems.">
  <meta name="generator" content="bookdown 0.3.16 and GitBook 2.6.7">

  <meta property="og:title" content="R-methods" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://github.com/kmcconeghy/R-Methods" />
  
  <meta property="og:description" content="A collection of working papers covering various statistical, analytical or causal inference problems." />
  <meta name="github-repo" content="/kmcconeghy/R-Methods" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="R-methods" />
  
  <meta name="twitter:description" content="A collection of working papers covering various statistical, analytical or causal inference problems." />
  

<meta name="author" content="Kevin W. McConeghy">


<meta name="date" content="2017-03-31">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="ggplot2-examples.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R-methods</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="heteroskedastic-cluster-robust-standard-errors.html"><a href="heteroskedastic-cluster-robust-standard-errors.html"><i class="fa fa-check"></i><b>1</b> Heteroskedastic &amp; Cluster Robust Standard Errors</a><ul>
<li class="chapter" data-level="1.1" data-path="heteroskedastic-cluster-robust-standard-errors.html"><a href="heteroskedastic-cluster-robust-standard-errors.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1.1" data-path="heteroskedastic-cluster-robust-standard-errors.html"><a href="heteroskedastic-cluster-robust-standard-errors.html#packages-to-use"><i class="fa fa-check"></i><b>1.1.1</b> Packages to use</a></li>
<li class="chapter" data-level="1.1.2" data-path="heteroskedastic-cluster-robust-standard-errors.html"><a href="heteroskedastic-cluster-robust-standard-errors.html#test-data"><i class="fa fa-check"></i><b>1.1.2</b> Test Data</a></li>
<li class="chapter" data-level="1.1.3" data-path="heteroskedastic-cluster-robust-standard-errors.html"><a href="heteroskedastic-cluster-robust-standard-errors.html#other-references"><i class="fa fa-check"></i><b>1.1.3</b> Other References</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="heteroskedastic-cluster-robust-standard-errors.html"><a href="heteroskedastic-cluster-robust-standard-errors.html#rs-calculation-of-standard-errors"><i class="fa fa-check"></i><b>1.2</b> R’s calculation of standard errors</a></li>
<li class="chapter" data-level="1.3" data-path="heteroskedastic-cluster-robust-standard-errors.html"><a href="heteroskedastic-cluster-robust-standard-errors.html#heteroskedascity"><i class="fa fa-check"></i><b>1.3</b> Heteroskedascity</a></li>
<li class="chapter" data-level="1.4" data-path="heteroskedastic-cluster-robust-standard-errors.html"><a href="heteroskedastic-cluster-robust-standard-errors.html#clustering"><i class="fa fa-check"></i><b>1.4</b> Clustering</a></li>
<li class="chapter" data-level="1.5" data-path="heteroskedastic-cluster-robust-standard-errors.html"><a href="heteroskedastic-cluster-robust-standard-errors.html#stata-comparison"><i class="fa fa-check"></i><b>1.5</b> Stata comparison</a></li>
<li class="chapter" data-level="1.6" data-path="heteroskedastic-cluster-robust-standard-errors.html"><a href="heteroskedastic-cluster-robust-standard-errors.html#test-data-1"><i class="fa fa-check"></i><b>1.6</b> Test data</a></li>
<li class="chapter" data-level="1.7" data-path="heteroskedastic-cluster-robust-standard-errors.html"><a href="heteroskedastic-cluster-robust-standard-errors.html#standard-least-squares-with-homoskedasctic-standard-errors"><i class="fa fa-check"></i><b>1.7</b> Standard Least Squares with homoskedasctic standard errors</a></li>
<li class="chapter" data-level="1.8" data-path="heteroskedastic-cluster-robust-standard-errors.html"><a href="heteroskedastic-cluster-robust-standard-errors.html#heteroskedastic-consistent-errors-in-r"><i class="fa fa-check"></i><b>1.8</b> Heteroskedastic consistent errors in R</a></li>
<li class="chapter" data-level="1.9" data-path="heteroskedastic-cluster-robust-standard-errors.html"><a href="heteroskedastic-cluster-robust-standard-errors.html#cluster-robust-errors-in-r"><i class="fa fa-check"></i><b>1.9</b> Cluster robust errors in R</a></li>
<li class="chapter" data-level="1.10" data-path="heteroskedastic-cluster-robust-standard-errors.html"><a href="heteroskedastic-cluster-robust-standard-errors.html#block-bootstrapping"><i class="fa fa-check"></i><b>1.10</b> Block bootstrapping</a><ul>
<li class="chapter" data-level="1.10.1" data-path="heteroskedastic-cluster-robust-standard-errors.html"><a href="heteroskedastic-cluster-robust-standard-errors.html#bootstrap-program"><i class="fa fa-check"></i><b>1.10.1</b> Bootstrap Program</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="heteroskedastic-cluster-robust-standard-errors.html"><a href="heteroskedastic-cluster-robust-standard-errors.html#acknowledgements"><i class="fa fa-check"></i><b>1.11</b> Acknowledgements</a></li>
<li class="chapter" data-level="1.12" data-path="heteroskedastic-cluster-robust-standard-errors.html"><a href="heteroskedastic-cluster-robust-standard-errors.html#bibliography"><i class="fa fa-check"></i><b>1.12</b> Bibliography</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ggplot2-examples.html"><a href="ggplot2-examples.html"><i class="fa fa-check"></i><b>2</b> ggplot2 Examples</a><ul>
<li class="chapter" data-level="2.1" data-path="ggplot2-examples.html"><a href="ggplot2-examples.html#introduction-1"><i class="fa fa-check"></i><b>2.1</b> Introduction</a><ul>
<li class="chapter" data-level="2.1.1" data-path="ggplot2-examples.html"><a href="ggplot2-examples.html#packages-to-use-1"><i class="fa fa-check"></i><b>2.1.1</b> Packages to use</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R-methods</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="heteroskedastic-cluster-robust-standard-errors" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Heteroskedastic &amp; Cluster Robust Standard Errors</h1>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">1.1</span> Introduction</h2>
<p>In this chapter we are evaluating R’s capability to compute different kinds of standard errors. Like with many things, R has extensive flexibility here but can be daunting when you want a quick option. To bring this flexibility down to earth, I lay out the background, provide practical recommendations, user-written commands and benchmark to STATA.</p>
<div id="packages-to-use" class="section level3">
<h3><span class="header-section-number">1.1.1</span> Packages to use</h3>
<pre>
 R version 3.3.2 (2016-10-31)
 Platform: x86_64-w64-mingw32/x64 (64-bit)
 Running under: Windows 10 x64 (build 14393)
 
 attached base packages:
 [1] stats     graphics  grDevices utils     datasets  base     
 
 other attached packages:
  [1] knitr_1.15.17     boot_1.3-18       lmtest_0.9-35    
  [4] zoo_1.7-14        sandwich_2.3-4    Scotty_0.0.0.9000
  [7] Hmisc_4.0-2       Formula_1.2-1     survival_2.40-1  
 [10] lattice_0.20-34   dplyr_0.5.0       purrr_0.2.2      
 [13] readr_1.1.0       tidyr_0.6.1       tibble_1.2       
 [16] ggplot2_2.2.1     tidyverse_1.1.1  
 </pre>

<p>“Scotty” is my own package. “tidyverse” is Wickam et al. general suite of packages/commands to work with R. “Hmisc” is Frank Harrel’s miscellaneous commands, many of which are quite useful.</p>
<p>“sandwich”, “lmtest” and “boot” are specifically relevant to this chapter in order to compute various standard errors (SE).</p>
</div>
<div id="test-data" class="section level3">
<h3><span class="header-section-number">1.1.2</span> Test Data</h3>
<p>The cluster data was obtained from:<br />
<a href="http://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/se/test_data.txt" class="uri">http://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/se/test_data.txt</a></p>
</div>
<div id="other-references" class="section level3">
<h3><span class="header-section-number">1.1.3</span> Other References</h3>
</div>
</div>
<div id="rs-calculation-of-standard-errors" class="section level2">
<h2><span class="header-section-number">1.2</span> R’s calculation of standard errors</h2>
</div>
<div id="heteroskedascity" class="section level2">
<h2><span class="header-section-number">1.3</span> Heteroskedascity</h2>
<p><em>Heteroskedascity</em> in this context refers to a collection of random variables where a given sub-population will have different variability compared with others. Variability being variance or some other measure of dispersion. In constrast <em>homoskedascity</em> is when variance is constant across these subpopulations (Figure 1).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Generate Data  </span>
  x &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">500</span>)
  yHomo &lt;-<span class="st"> </span><span class="dv">2</span>*x +<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">500</span>)
  yHetero &lt;-<span class="st"> </span><span class="dv">2</span>*x +<span class="st"> </span>x*<span class="kw">rnorm</span>(<span class="dv">500</span>) +<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">500</span>)
  df &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">cbind</span>(x, yHomo, yHetero))

<span class="co">#Scatter and Fitted Line </span>
<span class="kw">ggplot</span>(<span class="dt">data=</span>df, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>yHomo)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() +
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&#39;lm&#39;</span>, <span class="dt">se=</span>F) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;X variable&quot;</span>) +
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="01-vcovHC_files/figure-html/testdataHomo-1.png" width="672" /></p>
<p><strong>Figure 1.</strong> Example of homoskedascity. Note how data points appear to be randomly scattered around line of best fit, and that the dispersion <em>appears</em> constant across the range of X variable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Scatter and Fitted Line </span>
<span class="kw">ggplot</span>(<span class="dt">data=</span>df, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>yHetero)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() +
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&#39;lm&#39;</span>, <span class="dt">se=</span>F) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;X variable&quot;</span>) +
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="01-vcovHC_files/figure-html/testdataHetero-1.png" width="672" /></p>
<p><strong>Figure 2.</strong> Example of heteroskedascity. See how the dispersion appears greater as X increases.</p>
<p><span class="citation">Angrist and Pischke (<a href="#ref-angrist2008mostly">2008</a>)</span></p>
</div>
<div id="clustering" class="section level2">
<h2><span class="header-section-number">1.4</span> Clustering</h2>
<p><span class="citation">Bertrand M (<a href="#ref-Bertrand04howmuch">2004</a>)</span></p>
</div>
<div id="stata-comparison" class="section level2">
<h2><span class="header-section-number">1.5</span> Stata comparison</h2>
<p>A full discussion of STATA programming can be seen here: <a href="http://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/se/se_programming.htm" class="uri">http://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/se/se_programming.htm</a><br />
STATA blog:<br />
<a href="http://www.stata.com/support/faqs/statistics/standard-errors-and-vce-cluster-option/" class="uri">http://www.stata.com/support/faqs/statistics/standard-errors-and-vce-cluster-option/</a></p>
<p>Briefly: In Stata one can specify a variance-covariance matrix that is heteroskedastic consistent with the <em>vce(robust)</em> option in regression models.</p>
<p>e.g. robust option in STATA</p>
<pre><code>regress y x, vce(robust)</code></pre>
<p>A Huber-White variance-covariance matrix can also be computed by some group with the <strong>vce(cluster <em>group</em>)</strong> option in regression models.</p>
<p>e.g. cluster option in STATA</p>
<pre><code>regress y x, vce(cluster group)</code></pre>
<p>See:<br />
<a href="http://www.stata.com/support/faqs/statistics/standard-errors-and-vce-cluster-option/" class="uri">http://www.stata.com/support/faqs/statistics/standard-errors-and-vce-cluster-option/</a></p>
</div>
<div id="test-data-1" class="section level2">
<h2><span class="header-section-number">1.6</span> Test data</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">url &lt;-<span class="st"> &quot;http://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/se/test_data.txt&quot;</span>
df &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(<span class="kw">read.table</span>(url))
<span class="kw">print</span>(<span class="st">&quot;Head of test dataframe&quot;</span>)</code></pre></div>
<pre><code>## [1] &quot;Head of test dataframe&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">names</span>(df) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;group&quot;</span>, <span class="st">&quot;year&quot;</span>, <span class="st">&quot;x&quot;</span>, <span class="st">&quot;y&quot;</span>)
<span class="kw">head</span>(df)</code></pre></div>
<pre><code>## # A tibble: 6 × 4
##   group  year          x          y
##   &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;      &lt;dbl&gt;
## 1     1     1 -1.1139730  2.2515350
## 2     1     2 -0.0808538  1.2423460
## 3     1     3 -0.2376072 -1.4263760
## 4     1     4 -0.1524857 -1.1093940
## 5     1     5 -0.0014262  0.9146864
## 6     1     6 -1.2127370 -1.4246860</code></pre>
<p>This data represent financial information. As a benchmark I will use a widely available set financial data.(<span class="citation">Petersen (<a href="#ref-peterson2009">2009</a>)</span>) Several online posts compare this data using different specifications and software.</p>
<p>The expected results we will recreate are given here: <a href="http://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/se/test_data.htm" class="uri">http://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/se/test_data.htm</a></p>
</div>
<div id="standard-least-squares-with-homoskedasctic-standard-errors" class="section level2">
<h2><span class="header-section-number">1.7</span> Standard Least Squares with homoskedasctic standard errors</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(y ~<span class="st"> </span>x, <span class="dt">data =</span> df)
<span class="kw">coeftest</span>(m1)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 0.029680   0.028359  1.0466   0.2954    
## x           1.034833   0.028583 36.2041   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>These are the results with Table “OLS Coefficients and Standard Errors”. R computes the regression coefficients with <span class="math inline">\(( \textbf{X}&#39;\textbf{X})^{-1}\textbf{X}&#39;\textbf{y}\)</span> i.e. the coefficient is a function of X and y. Variance in general is computed like so: <span class="math inline">\(Var(X) = E[X − E(X)]^2 = E[(X − E(X)) (X − E(X))]\)</span></p>
<p>In a regression framework you compute standard errors by taking the square root of the diagonal elements of the variance-covariance matrix.</p>
<p>Equation 1. Covariance matrix of the error term <span class="math inline">\(u\)</span> <span class="math inline">\(E[{uu}&#39;|\textbf{X}] = \mathbf{\Sigma_{u}}\)</span></p>
<p>Equation 2.<br />
<span class="math inline">\(\mathbf{\Sigma_{u}} = \sigma^2 I_{N}\)</span></p>
<p>Equation 3. Expectation of the variance of <span class="math inline">\(\beta\)</span> conditional on X.<br />
<span class="math inline">\(\textrm{Var}[\hat{\mathbf{\beta}}|\textbf{X}] = (\textbf{X}&#39;\textbf{X})^{-1}(\textbf{X}&#39; \mathbf{\Sigma_{u}} \textbf{X}) (\textbf{X}&#39;\textbf{X})^{-1}\)</span></p>
<p>Under the assumption of independent and identically distributed errors and homoskedascity, Equation 3 is simplified to equation 4 (transpose matrix, using diagonal elements).</p>
<p>Equation 4. iid assumed <span class="math inline">\(\textrm{Var}[\hat{\mathbf{\beta}}|\textbf{X}] = \sigma_{u}^{2}(\textbf{X}&#39;\textbf{X})^{-1}\)</span></p>
<p>Assuming <span class="math inline">\(\sigma_u^2\)</span> is fixed but unknown, and equation to esimate <span class="math inline">\(s^2\)</span> can be used:</p>
<p>Equation 5. standard error</p>
<p><span class="math inline">\(s^2 = \frac{\sum_{i=1}^n e_i^2}{n-k}\)</span></p>
<p>Where <span class="math inline">\(e\)</span> squared residuals, <span class="math inline">\(n\)</span> is the sample size, and <span class="math inline">\(k\)</span> are the number of regressors.</p>
<p>The Standard errors above can be replicated manually like so:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># get X matrix/predictors</span>
X &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(m1)
<span class="co"># number of obs</span>
n &lt;-<span class="st"> </span><span class="kw">dim</span>(X)[<span class="dv">1</span>]
<span class="co"># n of predictors</span>
k &lt;-<span class="st"> </span><span class="kw">dim</span>(X)[<span class="dv">2</span>]
<span class="co"># calculate stan errs as in the above</span>
<span class="co"># sq root of diag elements in vcov</span>
se &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">diag</span>(<span class="kw">solve</span>(<span class="kw">crossprod</span>(X)) *<span class="st"> </span><span class="kw">as.numeric</span>(<span class="kw">crossprod</span>(<span class="kw">resid</span>(m1))/(n-k))))
se</code></pre></div>
<pre><code>## (Intercept)           x 
##  0.02835932  0.02858329</code></pre>
</div>
<div id="heteroskedastic-consistent-errors-in-r" class="section level2">
<h2><span class="header-section-number">1.8</span> Heteroskedastic consistent errors in R</h2>
</div>
<div id="cluster-robust-errors-in-r" class="section level2">
<h2><span class="header-section-number">1.9</span> Cluster robust errors in R</h2>
</div>
<div id="block-bootstrapping" class="section level2">
<h2><span class="header-section-number">1.10</span> Block bootstrapping</h2>
<p>An alternative to computing special variance-covariance matrices is non-parametric “block” bootstrapping. To do this, you perform a bootstrapping procedure where you sample the group or “block” instead of unit observation. This has been shown to be about as consistent and unbiased as the above sandwich estimators, and may be advantgeous when the number of clusters is small.<span class="citation">Bertrand M (<a href="#ref-Bertrand04howmuch">2004</a>)</span></p>
<div id="bootstrap-program" class="section level3">
<h3><span class="header-section-number">1.10.1</span> Bootstrap Program</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Boot.ATE &lt;-<span class="st"> </span>function (model, treat, <span class="dt">R =</span> <span class="dv">250</span>, <span class="dt">block =</span> <span class="st">&quot;&quot;</span>, df) 
{
  <span class="kw">require</span>(boot)
  <span class="kw">require</span>(dplyr)
  family &lt;-<span class="st"> </span>model$family
  if (block ==<span class="st"> &quot;&quot;</span>) {
    boot.mod &lt;-<span class="st"> </span>function(x, i, model, treat) {
      samp.df &lt;-<span class="st"> </span>x[i, ]
      samp.glm &lt;-<span class="st"> </span><span class="kw">try</span>(<span class="kw">glm</span>(model, <span class="dt">data =</span> samp.df, <span class="dt">family =</span> family))
      if (<span class="kw">inherits</span>(samp.glm, <span class="st">&quot;try-error&quot;</span>)) {
        coef &lt;-<span class="st"> </span><span class="ot">NA</span>
        ate &lt;-<span class="st"> </span><span class="ot">NA</span>
        rr &lt;-<span class="st"> </span><span class="ot">NA</span>
        <span class="kw">c</span>(coef, ate, rr)
      }
      else {
        df2 &lt;-<span class="st"> </span>samp.df
        df2[, <span class="kw">paste</span>(treat)] =<span class="st"> </span><span class="dv">1</span>
        pred1. &lt;-<span class="st"> </span><span class="kw">predict.glm</span>(samp.glm, <span class="dt">newdata =</span> df2, 
          <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
        df2[, <span class="kw">paste</span>(treat)] =<span class="st"> </span><span class="dv">0</span>
        pred0. &lt;-<span class="st"> </span><span class="kw">predict.glm</span>(samp.glm, <span class="dt">newdata =</span> df2, 
          <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
        coef &lt;-<span class="st"> </span>samp.glm$coefficients[<span class="kw">paste0</span>(treat)]
        ate &lt;-<span class="st"> </span><span class="kw">mean</span>(pred1.) -<span class="st"> </span><span class="kw">mean</span>(pred0.)
        rr &lt;-<span class="st"> </span><span class="kw">mean</span>(pred1.)/<span class="kw">mean</span>(pred0.)
        <span class="kw">c</span>(coef, ate, rr)
      }
    }
    boot.m &lt;-<span class="st"> </span><span class="kw">boot</span>(<span class="dt">data =</span> df, <span class="dt">statistic =</span> boot.mod, <span class="dt">R =</span> R, 
      <span class="dt">model =</span> model, <span class="dt">treat =</span> treat)
  }
  else {
    Groups =<span class="st"> </span><span class="kw">unique</span>(df[, <span class="kw">paste</span>(block)])
    boot.mod &lt;-<span class="st"> </span>function(x, i, model, treat, df, block, 
      <span class="dt">iter =</span> <span class="dv">0</span>) {
      block.df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">group =</span> x[i])
      <span class="kw">names</span>(block.df) =<span class="st"> </span>block
      samp.df &lt;-<span class="st"> </span><span class="kw">left_join</span>(block.df, df, <span class="dt">by =</span> block)
      samp.glm &lt;-<span class="st"> </span><span class="kw">try</span>(<span class="kw">glm</span>(model, <span class="dt">data =</span> samp.df, <span class="dt">family =</span> family))
      if (<span class="kw">inherits</span>(samp.glm, <span class="st">&quot;try-error&quot;</span>)) {
        coef &lt;-<span class="st"> </span><span class="ot">NA</span>
        ate &lt;-<span class="st"> </span><span class="ot">NA</span>
        rr &lt;-<span class="st"> </span><span class="ot">NA</span>
        <span class="kw">c</span>(coef, ate, rr)
      }
      else {
        df2 &lt;-<span class="st"> </span>samp.df
        df2[, <span class="kw">paste</span>(treat)] =<span class="st"> </span><span class="dv">1</span>
        pred1. &lt;-<span class="st"> </span><span class="kw">predict.glm</span>(samp.glm, <span class="dt">newdata =</span> df2, 
          <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
        df2[, <span class="kw">paste</span>(treat)] =<span class="st"> </span><span class="dv">0</span>
        pred0. &lt;-<span class="st"> </span><span class="kw">predict.glm</span>(samp.glm, <span class="dt">newdata =</span> df2, 
          <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
        coef &lt;-<span class="st"> </span>samp.glm$coefficients[<span class="kw">paste0</span>(treat)]
        ate &lt;-<span class="st"> </span><span class="kw">mean</span>(pred1.) -<span class="st"> </span><span class="kw">mean</span>(pred0.)
        rr &lt;-<span class="st"> </span><span class="kw">mean</span>(pred1.)/<span class="kw">mean</span>(pred0.)
        <span class="kw">c</span>(coef, ate, rr)
      }
    }
    boot.m &lt;-<span class="st"> </span><span class="kw">boot</span>(<span class="dt">data =</span> Groups, <span class="dt">statistic =</span> boot.mod, 
      <span class="dt">R =</span> R, <span class="dt">model =</span> model, <span class="dt">treat =</span> treat, <span class="dt">df =</span> df, <span class="dt">block =</span> block)
  }
  m1.confint &lt;-<span class="st"> </span><span class="kw">c</span>(model$coefficients[<span class="kw">paste0</span>(treat)], <span class="kw">confint</span>(model, 
    treat, <span class="dt">level =</span> <span class="fl">0.95</span>))
  coeff =<span class="st"> </span><span class="kw">boot.ci</span>(boot.m, <span class="dt">index =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;perc&quot;</span>)
  coeff =<span class="st"> </span><span class="kw">c</span>(<span class="kw">median</span>(boot.m$t[, <span class="dv">1</span>]), coeff$percent[, <span class="dv">4</span>], coeff$percent[, 
    <span class="dv">5</span>])
  <span class="kw">names</span>(coeff) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Coeff.&quot;</span>, <span class="st">&quot;2.5%&quot;</span>, <span class="st">&quot;97.5%&quot;</span>)
  ate =<span class="st"> </span><span class="kw">boot.ci</span>(boot.m, <span class="dt">index =</span> <span class="dv">2</span>, <span class="dt">type =</span> <span class="st">&quot;perc&quot;</span>)
  ate =<span class="st"> </span><span class="kw">c</span>(<span class="kw">median</span>(boot.m$t[, <span class="dv">2</span>]), ate$percent[, <span class="dv">4</span>], ate$percent[, 
    <span class="dv">5</span>])
  <span class="kw">names</span>(ate) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;ATE&quot;</span>, <span class="st">&quot;2.5%&quot;</span>, <span class="st">&quot;97.5%&quot;</span>)
  rr =<span class="st"> </span><span class="kw">boot.ci</span>(boot.m, <span class="dt">index =</span> <span class="dv">3</span>, <span class="dt">type =</span> <span class="st">&quot;perc&quot;</span>)
  rr =<span class="st"> </span><span class="kw">c</span>(<span class="kw">median</span>(boot.m$t[, <span class="dv">3</span>]), rr$percent[, <span class="dv">4</span>], rr$percent[, 
    <span class="dv">5</span>])
  <span class="kw">names</span>(rr) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Rr&quot;</span>, <span class="st">&quot;2.5%&quot;</span>, <span class="st">&quot;97.5%&quot;</span>)
  boot.iter =<span class="st"> </span>boot.m$t
  res =<span class="st"> </span><span class="kw">list</span>(<span class="dt">level =</span> <span class="fl">0.95</span>, <span class="dt">model_ci =</span> m1.confint, <span class="dt">coeff =</span> coeff, 
    <span class="dt">ate =</span> ate, <span class="dt">rr =</span> rr, <span class="dt">boots =</span> boot.iter)
  <span class="kw">return</span>(res)
}</code></pre></div>
</div>
</div>
<div id="acknowledgements" class="section level2">
<h2><span class="header-section-number">1.11</span> Acknowledgements</h2>
<p>This chapter is heavily adapted from several StackExchange and other blog posts. See:<br />
<a href="http://www.richard-bluhm.com/clustered-ses-in-r-and-stata-2/" class="uri">http://www.richard-bluhm.com/clustered-ses-in-r-and-stata-2/</a><br />
<a href="http://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/standarderror_extra_tables.pdf" class="uri">http://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/standarderror_extra_tables.pdf</a><br />
<a href="https://sites.google.com/site/waynelinchang/r-code" class="uri">https://sites.google.com/site/waynelinchang/r-code</a><br />
<a href="http://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/se/test_data.htm" class="uri">http://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/se/test_data.htm</a><br />
<a href="https://thetarzan.wordpress.com/2011/05/28/heteroskedasticity-robust-and-clustered-standard-errors-in-r/" class="uri">https://thetarzan.wordpress.com/2011/05/28/heteroskedasticity-robust-and-clustered-standard-errors-in-r/</a></p>
</div>
<div id="bibliography" class="section level2">
<h2><span class="header-section-number">1.12</span> Bibliography</h2>
<p><span class="citation">R Core Team (<a href="#ref-R-base">2016</a>)</span></p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-angrist2008mostly">
<p>Angrist, J.D., and J.S. Pischke. 2008. <em>Mostly Harmless Econometrics: An Empiricist’s Companion</em>. Princeton University Press. <a href="https://books.google.com/books?id=ztXL21Xd8v8C" class="uri">https://books.google.com/books?id=ztXL21Xd8v8C</a>.</p>
</div>
<div id="ref-Bertrand04howmuch">
<p>Bertrand M, Mullainathan S, Duflo E. 2004. “How Much Should We Trust Differences-in-Differences Estimates?” <em>QUARTERLY JOURNAL OF ECONOMICS</em>, 24975.</p>
</div>
<div id="ref-peterson2009">
<p>Petersen, MA. 2009. “Estimating Standard Errors in Finance Panel Data Sets: Comparing Approaches.” <em>Review of Financial Studies</em> 22: 435–80.</p>
</div>
<div id="ref-R-base">
<p>R Core Team. 2016. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/" class="uri">https://www.R-project.org/</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ggplot2-examples.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
